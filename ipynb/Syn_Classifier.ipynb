{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switching directories for easy access to the data\n",
    "data = '/Users/alexchoe/Desktop/Capstone/m2py-master/data/all_abstracts_model/'\n",
    "os.chdir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening contents of Word2Vec model\n",
    "model = Word2Vec.load(\"all_abstract_model.model\")\n",
    "vocabulary = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.51539   ,   4.103919  ,  -1.8394607 ,  -6.114477  ,\n",
       "         6.1308594 ,   6.0427675 ,  -1.1978918 ,   1.855273  ,\n",
       "        -4.160244  ,  -3.742103  ,  -0.5794198 ,   9.883354  ,\n",
       "        -4.3117127 ,   4.3782854 ,   3.5364165 ,  -4.9079742 ,\n",
       "        -2.0147028 ,   5.517852  ,  -2.5264072 ,   0.60432535,\n",
       "        -0.90231055,   2.0508857 ,  -1.0533296 ,  -4.2132974 ,\n",
       "         4.2740326 ,  -1.8519586 ,   2.927174  ,  -1.760242  ,\n",
       "       -13.595478  ,   6.390037  ,   5.449058  ,   1.0620196 ,\n",
       "         1.1603653 ,  -1.8674527 ,  -7.909827  ,   3.757318  ,\n",
       "        -0.7085782 ,  -1.8104229 ,  -0.7972807 ,   0.24420857,\n",
       "        -0.02632353,  -5.917606  ,  10.481008  ,  -3.1318085 ,\n",
       "        -1.7313521 ,   2.7741985 ,   3.4522643 ,  -4.4935923 ,\n",
       "         1.5952134 ,   0.79401314], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.__getitem__('study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/alexchoe/Desktop/Capstone/BETO2020-master/data/carbon/'\n",
    "os.chdir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking in data as a dataframe for easy pre-processing\n",
    "df = pd.read_excel('Carbon_SynAntList_Full_Refined.xlsx', skiprows = 1, nrows=2000)\n",
    "carbon_df = df.rename(columns = {'Unnamed: 0':'index', 0:'word 1', 1:'word 2', 2:'relationship', 'Unnamed: 4':'label'})\n",
    "carbon_df = carbon_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask to only keep strong word pair relationships\n",
    "condition = carbon_df['label'] != 0\n",
    "keep = (condition)\n",
    "carbon_df = carbon_df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>relationship</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>original</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>carbon</td>\n",
       "      <td>graphite</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>carbon</td>\n",
       "      <td>soot</td>\n",
       "      <td>syn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>carbon</td>\n",
       "      <td>imitate</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>carbon</td>\n",
       "      <td>paint</td>\n",
       "      <td>syn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>infinite</td>\n",
       "      <td>ephemeral</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>infinite</td>\n",
       "      <td>finite</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>infinite</td>\n",
       "      <td>intermittent</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>infinite</td>\n",
       "      <td>limited</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>infinite</td>\n",
       "      <td>little</td>\n",
       "      <td>ant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index    word 1        word 2 relationship label\n",
       "0         0    carbon      original          ant     0\n",
       "1         1    carbon      graphite          syn     1\n",
       "2         2    carbon          soot          syn     1\n",
       "3         3    carbon       imitate          syn     0\n",
       "4         4    carbon         paint          syn     0\n",
       "...     ...       ...           ...          ...   ...\n",
       "1995   1995  infinite     ephemeral          ant     0\n",
       "1996   1996  infinite        finite          ant     0\n",
       "1997   1997  infinite  intermittent          ant     0\n",
       "1998   1998  infinite       limited          ant     0\n",
       "1999   1999  infinite        little          ant     0\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carbon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carbon'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carbon_df['word 1'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-1b1c4fe5fc5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Restructuring the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarbon_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcarbon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarbon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcarbon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word 2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarbon_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word 2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#Restructuring the dataframe\n",
    "for i in range(len(carbon_df)):\n",
    "    carbon_df['word 1'].iloc[i] = model.wv.__getitem__(str(carbon_df['word 1'].iloc[i]))\n",
    "    carbon_df['word 2'].iloc[i] = model.wv.__getitem__(str(carbon_df['word 2'].iloc[i]))\n",
    "    \n",
    "    if carbon_df['relationship'].iloc[i] == str('syn') & carbon_df['label'].iloc[i] == 1:\n",
    "        carbon_df['relationship'].iloc[i] = 1\n",
    "    else: \n",
    "        carbon_df['relationship'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "learning_rate = 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = W2V_df[['Word 1', 'Word 2']] #Input features used to make predictions\n",
    "Y = W2V_df[['Relationship']] #Target features to be predicted \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, shuffle = True) #split dataset into separate testing and training datasets\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train.values.astype(np.float32)) #convert pd.DataFrame -> np.ndarray -> torch.tensor\n",
    "syn_train_tensor = torch.tensor(syn_train.values.astype(np.float32))\n",
    "ant_train_tensor = torch.tensor(syn_train.values.astype(np.float32))\n",
    "\n",
    "#create tensor with features and targets\n",
    "train_tensor = torch.utils.data.TensorDataset(x_train_tensor, syn_train_tensor, nonsyn_train_tensor)\n",
    "#create iterable dataset with batches\n",
    "training_data_set = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.values.astype(np.float32))\n",
    "syn_test_tensor = torch.tensor(syn_test.values.astype(np.float32))\n",
    "nonsyn_test_tensor = torch.tensor(nonsyn_test.values.astype(np.float32))\n",
    "\n",
    "test_tensor = torch.utils.data.TensorDataset(x_test_tensor, syn_test_tensor)\n",
    "testing_data_set = torch.utils.data.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the neural network\n",
    "class syn_NN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dims, out_dims):\n",
    "        \n",
    "        #embedding layer\n",
    "        self.em_layer = nn.Linear(in_dims, out_dims)\n",
    "\n",
    "        #hidden layers\n",
    "        self.h_layer1 = nn.Linear(out_dims, 32)\n",
    "        self.h_layer2 = nn.Linear(32, 16)\n",
    "        \n",
    "        #output layer\n",
    "        self.o_layer = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #data enters embedding layer\n",
    "        out = self.em_layer(x)\n",
    "        \n",
    "        #embedded data is passed to hidden layers\n",
    "        out = self.h_layer1(out)\n",
    "        out = self.h_layer2(out)\n",
    "        \n",
    "        #embedded data is passed to output layers\n",
    "        syn_out = self.o_layer(out)\n",
    "        \n",
    "        return syn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, training_data_set, optimizer):\n",
    "    train_epoch_loss = []\n",
    "    syn_train_epoch_loss = []\n",
    "    \n",
    "    syn_losses = []\n",
    "    train_total = 0\n",
    "    \n",
    "    #switch model to training mode\n",
    "    model.train()\n",
    "    syn_criterion = nn.MSELoss()\n",
    "    \n",
    "    for features, labels in training_data_set:\n",
    "        \n",
    "        model.zero_grad() #zero out any gradients from prior loops \n",
    "        syn_out = model(features) #gather model predictions for this loop\n",
    "        \n",
    "        #calculate error in the predictions\n",
    "        syn_loss = syn_criterion(syn_out, labels)\n",
    "        \n",
    "        total_loss = syn_loss\n",
    "        \n",
    "        #BACKPROPAGATE LIKE A MF\n",
    "        torch.autograd.backward([syn_loss])\n",
    "        optimizer.step()\n",
    "        \n",
    "        #save loss for this batch\n",
    "        train_losses.append(total_loss.item())\n",
    "        train_total+=1\n",
    "        \n",
    "        syn_train_losses.append(pce_loss.item())\n",
    "        \n",
    "    #calculate and save total error for this epoch of training\n",
    "    epoch_loss = sum(train_losses)/train_total\n",
    "    train_epoch_loss.append(epoch_loss)\n",
    "    \n",
    "    syn_train_epoch_loss.append(sum(ff_train_losses)/train_total)\n",
    "    \n",
    "    #update progress bar\n",
    "    print(f\"Total Epoch Training Loss = {train_epoch_loss}\")\n",
    "    \n",
    "    return train_epoch_loss, syn_train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, testing_data_set, optimizer):\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    \n",
    "    syn_criterion = nn.MSELoss(lower = 0, upper = 6)\n",
    "    #accuracy = PhysLoss.MAPE()\n",
    "\n",
    "    #don't update nodes during evaluation b/c not training\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        syn_test_losses = []\n",
    "        syn_test_acc_list = []\n",
    "        \n",
    "        test_total = 0\n",
    "\n",
    "        for inputs in testing_data_set:\n",
    "            inputs = inputs.to(device)\n",
    "            syn_labels = syn_labels.to(device)\n",
    "\n",
    "            syn_out = model(inputs)\n",
    "\n",
    "            # calculate loss per batch of testing data\n",
    "            syn_test_loss = syn_criterion(syn_out)\n",
    "            \n",
    "            test_loss = pce_test_loss + voc_test_loss + jsc_test_loss + ff_test_loss\n",
    "            \n",
    "            test_losses.append(test_loss.item())\n",
    "            syn_test_losses.append(syn_test_loss.item())\n",
    "            test_total += 1 \n",
    "\n",
    "            #syn_acc = accuracy(syn_out)\n",
    "            #syn_test_acc_list.append(syn_acc.item())\n",
    "\n",
    "        test_epoch_loss = sum(test_losses)/test_total\n",
    "        syn_test_epoch_loss = sum(syn_test_losses)/test_total\n",
    "        \n",
    "        #syn_epoch_acc = sum(syn_test_acc_list)/test_total\n",
    "\n",
    "        print(f\"Total Epoch Testing Loss = {test_epoch_loss}\")\n",
    "        #print(f\"Epoch MAPE: Syn = {syn_epoch_acc}\")\n",
    "    return test_epoch_loss, syn_test_epoch_loss #syn_epoch_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
